{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intruducción.\" data-toc-modified-id=\"Intruducción.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intruducción.</a></span></li><li><span><a href=\"#Estandarización-de-los-datos.\" data-toc-modified-id=\"Estandarización-de-los-datos.-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Estandarización de los datos.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Función-scale.\" data-toc-modified-id=\"Función-scale.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Función scale.</a></span></li><li><span><a href=\"#Clase-StandardScaler.\" data-toc-modified-id=\"Clase-StandardScaler.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Clase StandardScaler.</a></span></li></ul></li><li><span><a href=\"#Escalando-features-dentro-de-un-rango.\" data-toc-modified-id=\"Escalando-features-dentro-de-un-rango.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Escalando features dentro de un rango.</a></span></li><li><span><a href=\"#Transformaciones-no-lineales.\" data-toc-modified-id=\"Transformaciones-no-lineales.-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Transformaciones no lineales.</a></span></li><li><span><a href=\"#Normalización.\" data-toc-modified-id=\"Normalización.-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Normalización.</a></span></li><li><span><a href=\"#Binarización\" data-toc-modified-id=\"Binarización-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Binarización</a></span></li><li><span><a href=\"#Codificando-variables-alfanuméricas\" data-toc-modified-id=\"Codificando-variables-alfanuméricas-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Codificando variables alfanuméricas</a></span></li><li><span><a href=\"#Codificando-variables-categóricas.\" data-toc-modified-id=\"Codificando-variables-categóricas.-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Codificando variables categóricas.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Codificando-con-pandas.\" data-toc-modified-id=\"Codificando-con-pandas.-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Codificando con pandas.</a></span></li></ul></li><li><span><a href=\"#Imputando-valores-faltantes.\" data-toc-modified-id=\"Imputando-valores-faltantes.-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Imputando valores faltantes.</a></span></li><li><span><a href=\"#Generando-features-tipo-polinomio\" data-toc-modified-id=\"Generando-features-tipo-polinomio-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Generando features tipo polinomio</a></span></li><li><span><a href=\"#Transformaciones-a-medida.\" data-toc-modified-id=\"Transformaciones-a-medida.-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Transformaciones a medida.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intruducción.\n",
    "\n",
    "Existe una librería muy utilizada en trabajos de machine learning [denominada scikit-learn](http://scikit-learn.org/stable/){:target=\"_blank\"} que contiene multitud de procedimientos para realizar estudios estadísticos de los datos. En este post comenzamos la andadura de conocer esta librería, utilizando el enfoque de transformar las datos para conseguir determinados objetivos que faciliten el objetivo perseguido.\n",
    "\n",
    "En trabajos de  machine learning son muchas las ocasiones en las que se necesita trabajar con variables (features) que tengan una métrica similar de cara a poder realizar comparaciones fiables entre ellas.\n",
    "\n",
    "Para poder realziar este trabajo de una forma fácil y cómoda scikit-learn propociona una serie de procedimientos o funciones que se encargan de hacer un trabajo preparatotio de los datos antes de comenzar elcorrespondiente procesamiento.\n",
    "\n",
    "Todas estas técnicas son las que de una forma resumida se presentan en está sección, con la dinalidad de mostrar el lector un pequeño resumen sobre su uso, y después si se quieren ampliar conocimientos sobre determinado tema se puede acudir a la API de scikip-learn (en este caso concreto en el paquete ** sklearn.preprocessing** ) para tomar pleno conocimiento de todas las posibilidades que ofrece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estandarización de los datos.\n",
    "\n",
    "La estandarización de los datos consiste en emplear una técnica de tal manera que los datos resultantes tengan una media de cero y una desviación típica de 1. Lo más normal es que esta estandarización se realice sobre las columnas (axis=0), aunque scikt-learn presenta también la popsibilidad de hacerlo sobre las filas ( axis=1).\n",
    "\n",
    "Para conseguir este objetivo, lo que se hace es restar a todos los datos la media de los mismos y después escalarlos, para lo cual se divide el resultado anterior por la desviación típica de los datos originales.\n",
    "\n",
    "Hay que destacar que el comportamiento anterior es el que se hace por defecto, pero scikit-learn también ofrece la posibilidad de sólo restar la media ( es decir, centrar los datos ), o sólo dividir por la desviación típica ( es decir, escalar los datos).\n",
    "\n",
    "## Función scale.\n",
    "\n",
    "Para realizar estos trabajos, el paquete sklearn.preprocesing ofrece la función ** scale ** que trabaja de la forma que se muestra en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos a continuación que las columnas (features) obtenidas, tienen media cero y desviación típica 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tan sólo queremos restar la media, se haría de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.          1.66666667]\n",
      " [ 1.          0.         -0.33333333]\n",
      " [-1.          1.         -1.33333333]] \n",
      "\n",
      "Medias:  [0.00000000e+00 0.00000000e+00 7.40148683e-17] \n",
      "\n",
      "STD:  [0.81649658 0.81649658 1.24721913]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = preprocessing.scale(X_train, with_std=False)\n",
    "print(X_scaled, \"\\n\")\n",
    "print(\"Medias: \", X_scaled.mean(axis=0),\"\\n\")\n",
    "print(\"STD: \", X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase StandardScaler.\n",
    "\n",
    "El paquete preprocessing igualmente tiene una clase de utilidad muy interesante para realizar este tipo de tareas. Esta clase se denomina ** StandardScaler ** que permite calcular la media y desviación típica de los datos, para posteriormente hacer transformaciones de los mismos. Veamos a continuación un pequeño ejemplo sobre su uso.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "La media de las columnas es:  [1.         0.         0.33333333]\n",
      "La desviación típca de las columnas es:  [0.81649658 0.81649658 1.24721913] \n",
      "\n",
      "Ahora estadarizamos los datos por columnas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "print(scaler)\n",
    "print(\"La media de las columnas es: \",scaler.mean_ )\n",
    "print(\"La desviación típca de las columnas es: \", scaler.scale_,\"\\n\" )\n",
    "\n",
    "print(\"Ahora estadarizamos los datos por columnas\")\n",
    "scaler.transform(X_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tuvieramos los datos distribuidos es datos para el entrenamiento (data_train) y para el chequeo del modelo (data_test), si tificamos los datos de entrenamiento como se ha hecho anteriormente, también habría que hacerlo para los datos de chequeo y ese trabajo se haría de la siguiente manera:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.44948974,  1.22474487, -0.26726124]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[-1., 1., 0.]]\n",
    "X_test_transform=scaler.transform(X_test)\n",
    "X_test_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si una vez finalizado el proceso queremos deshacer las transformaciones que se han hecho de los datos, se haría de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_init=scaler.inverse_transform(X_test_transform)\n",
    "X_test_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalando features dentro de un rango.\n",
    "\n",
    "Una alternativa al proceso de estandarización que se ha visto en el apartado anterior consiste en escalar las variables dentro de un determinado rango de valores ( normalmente entre cero y uno ). Para realizar esta transformación scikit Learn ofrece dos clases súmamente practicas: **MinMaxScaler y MaxAbsScaler **.\n",
    "\n",
    "A continuación se muestra un ejemplo con la finalidad de clarificar su utilización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()  #Generamos una instancia de la clase\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train) #Se realiza la transformación\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se tuvieran datos \"train\" para el entrenamiento y \"test\" para la evaluación del modelo, estos últimos también habría que trasformarlos, para ello se haría el siguiente proceso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5       ,  0.        ,  1.66666667]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[ -3., -1.,  4.]])\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "X_test_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si por ejemplo quisiéramos hacer un escalado entre cero y tres, el mismo se haría con la siguiente instrucción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5, 0. , 3. ],\n",
       "       [3. , 1.5, 1. ],\n",
       "       [0. , 3. , 0. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler_0_3 = preprocessing.MinMaxScaler(feature_range=(0,3))\n",
    "X_train_minmax_0_3 = min_max_scaler_0_3.fit_transform(X_train) #Se realiza la transformación\n",
    "X_train_minmax_0_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos recuperar los valores orginales de la la última transformación, lo haríamos de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  2.],\n",
       "       [ 2.,  0.,  0.],\n",
       "       [ 0.,  1., -1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler_0_3.inverse_transform(X_train_minmax_0_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones no lineales.\n",
    "\n",
    "Este procedimiento consiste en otra forma diferente de transformar los datos para adaptarlos a las necesidades del procesamiento que en cada momento se necesite.\n",
    "\n",
    "Pra hacer este tipo de transformaciones scikit learn dispone de dos clases: QuantileTransformer y quantile_transform. En ambos casos, la salida de la transformación va a seguir una distribución uniforme o normal.\n",
    "\n",
    "En el caso de que la salida sea una distribución normal ( que es la opción por defecto ) hay que tener en cuenta que el valor de la variable va a coincidir con el precentil que indica su valor. Veamos esto con un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.3, 5.1, 5.8, 6.5, 7.9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()  #Cargo el fichero con los datos\n",
    "X, y = iris.data, iris.target #Cargos los datos y la respuesta ( o target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) #Divido los datos en train y test\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0) #Genero una instancia de QuantileTransformer\n",
    "X_train_trans = quantile_transformer.fit_transform(X_train) #Obtengo los datos ajustados\n",
    "X_test_trans = quantile_transformer.transform(X_test)\n",
    "np.percentile(X_train[:, 0], [0, 25, 50, 75, 100])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nota** : El código anterior debe ejecutarse con al menos la versión 0.19 de scikit learn, con versión 0.18 genera error, pues no conoce las clases QuantileTransformer y quantile_transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede verse en el código anterior, los percentiles 0, 25, 50, 75 y 100 para los valores de X_train sin transformar se encuentrar en los valores 4.3, 5.1, 5.8, 6.5 y 7.9 respectivamente. \n",
    "\n",
    "Sin embargo si utilizamos los datos transformados, entonces los valores de la variable coincide con el precentil correspondiente. Veamos esto con el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99999998e-08, 2.38738739e-01, 5.09009009e-01, 7.43243243e-01,\n",
       "       9.99999900e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(X_train_trans[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver el percentil cero coincide con el valor cero de la variable, el percentil 25 con el valor 0,25 de la variables...y así para el resto de los percentiles.\n",
    "\n",
    "Vamos a confirmar además que estos valores de los percentiles aproximadamente son los mismos para los valores de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4   5.125 5.75  6.175 7.3  ] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01351351, 0.25012513, 0.47972973, 0.6021021 , 0.94144144])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.percentile(X_test[:, 0], [0, 25, 50, 75, 100]),\"\\n\")\n",
    "\n",
    "\n",
    "np.percentile(X_test_trans[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de que se quiera hacer una trasformación a datos de una normal, se haría con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3       , 2.        , 1.        , 0.1       ],\n",
       "       [4.31491491, 2.02982983, 1.01491491, 0.1       ],\n",
       "       [4.32982983, 2.05965966, 1.02982983, 0.1       ],\n",
       "       ...,\n",
       "       [7.84034034, 4.34034034, 6.84034034, 2.5       ],\n",
       "       [7.87017017, 4.37017017, 6.87017017, 2.5       ],\n",
       "       [7.9       , 4.4       , 6.9       , 2.5       ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_transformer = preprocessing.QuantileTransformer(\n",
    "    output_distribution='normal', random_state=0)  #Aqui se indica que se desea una salida a una normal\n",
    "X_trans = quantile_transformer.fit_transform(X)\n",
    "quantile_transformer.quantiles_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización.\n",
    "\n",
    "El proceso de consiste en escalar los datos iniciales para conseguir que tengan una disribución uniforme. Este tipo de procedimientos es la base de [Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model), y es muy utilizado en clasificación de texto y en la obtención de clusters.\n",
    "\n",
    "Se utiliza la función *normalize* para ello y se pude usar la norma l1 o la norma l2. Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "\n",
    "X_normalized   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un proceso similar al anterior se puede conseguir utilizando la clase *Normalize* del paquete preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarización\n",
    "\n",
    "Con este proceso se va a hacer una transformación de la variables original en otra que solo posee los valores cero o uno ( es decir una variable de Bernuilli). Como valor por defecto para discriminar y asignar un valor cero o uno se toma el valor de cero. De esta forma los valores negativos de la variable original se les transforma aun valor cero y el resto tomarán un valor de 1. Si se quiere modificar el valor de corte ( es decir el cero asignado por defecto), se utilizará el parámetro \"threshold\".\n",
    "A continuación se pone un ejemplo sobre este tipo de transformación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizer(copy=True, threshold=0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "\n",
    "binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing\n",
    "print(binarizer)\n",
    "\n",
    "\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo cambiamos el valor de corte y en lugar de cero se le asigna 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizer(copy=True, threshold=1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer2 = preprocessing.Binarizer(threshold=1.0).fit(X)  # fit does nothing\n",
    "print(binarizer2)\n",
    "\n",
    "\n",
    "binarizer2.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** La función *binarize* facilita resultados similares, a los vistos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificando variables alfanuméricas\n",
    "\n",
    "En ocasiones las variables tomadas están codificadas con términos alfabéticos, por ejemplo si tomamos la variables sexo, la misma  puede venir en nuestro fichero de datos codificada con valores \"V\" para varones y \"M\" para mujeres. Estos valores deben ser convertidos a números para que sus valores puedan ser utilizados dentro de los procedimientos de machine learning empleados por scikit learning. En el siguiente apartado se muestra cómo poder conseguir esto utilizando numpy, o bien pandas.\n",
    "\n",
    "Lo primero que hacemos es importar estas importantes librerías para trabajar con python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después se procede a mostrar como obtener los resultados que se desean. En primer lugar se hará con scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder()\n",
      "[0 1 2 0 1 2] \n",
      "\n",
      "['a' 'b' 'c']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "a = np.array( ['a', 'b', 'c', 'a', 'b', 'c'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "print(le.fit(a))\n",
    "print(le.fit_transform(a),\"\\n\")\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se hará con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La codificación de esos valores sería la siguiente:\n",
      "[0 1 2 0 1 2]\n",
      "Lo valores alfabéticos a los que se refieren se obtienen de la siguiene manera:\n",
      "['a' 'b' 'c']\n"
     ]
    }
   ],
   "source": [
    "a = np.array(['a', 'b', 'c', 'a', 'b', 'c'])\n",
    "a_enc = pd.factorize(a)\n",
    "print(\"La codificación de esos valores sería la siguiente:\")\n",
    "print(a_enc[0])\n",
    "print(\"Lo valores alfabéticos a los que se refieren se obtienen de la siguiene manera:\")\n",
    "print(a_enc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra manera de codificar este tipo de variable es pasando a variables de tipo dummys, es decir que está representandas sólo por ceros o unos. Para hacer esto se utiliza la propiedad get_dummies de pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  1  0  0\n",
      "1  0  1  0\n",
      "2  0  0  1\n",
      "3  1  0  0\n",
      "4  0  1  0\n",
      "5  0  0  1\n"
     ]
    }
   ],
   "source": [
    "a = np.array(['a', 'b', 'c', 'a', 'b', 'c'])\n",
    "b = pd.get_dummies(a)\n",
    "print(b) # vemos que el primer valor queda codificado como 1 0 0; el segundo como 0 1 0 etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos una codificación de tipo [0 1 2...] se hará de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.values.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Codificando variables categóricas.\n",
    "\n",
    "En el apartado anterior, ya hemos visto cómo asignar valores numéricos a variables que están codificadas con literales. En el ejemplo anterior, tratábamos valores de \"V\" y \"M\", que pasaban a tener valores 0 ó 1. Si una variable categórica tuviera mayor número de categorias entonces el número de dígitos sería también mayor.\n",
    "\n",
    "Ahora que las variables categóricas ya están codificadas con datos numéricos, perfectamente estos vaolres podrían entrar a formar parte de las estrategias que utiliza scikit learn para construir los diferentes modelos, ahora bien hay que tener en cuenta que este tipo de codificación ( 1,2,3,.. por ejemplo) implica una escala de valores que en principio no tiene ningún sentido.\n",
    "\n",
    "Entonces para evitar este tipo de problemas y asignar a todos los valores posibles de una variable categórica el mismo valor, se emplea en estadística las denominadas *variables dummy* integradas por valores de cero o uno. La estrategia es la siguiente: Se construyen tantas nuevas variables como como diferentes valores pudiera tener la variable categórica, y entonces para una determinada observación se asigna cero a todas estas nevas variable salvo a una que se le asigna un uno y es la columna que representa la categoría que se tiene para esa determinada observación. Veamos esto con un ejemplo.\n",
    "\n",
    "Supongamos que tenemos una variable denominada \"sexo\". Sería una variable categórica con valores por ejemplo 1 y 2. Como la variable sexo tiene dos categorías, se construirian dos nuevas variables, llamadas por ejemplo sexo_1 y sexo_2. Entonoces la codificación en las nuevas variables se muestra en los siguientes ejemplos:\n",
    "\n",
    "\n",
    "| Sexo | Sexo_1 | Sexo_2 |\n",
    "|------|--------|--------|\n",
    "|   1  |    1   |    0   |\n",
    "|   2  |    0   |    1   |\n",
    "|   2  |    0   |    1   |\n",
    "|   1  |    1   |    0   |\n",
    "|   1  |    1   |    0   |\n",
    "|   2  |    0   |    1   |\n",
    "\n",
    "Para realizar todo este tipo de procesamientos, el paquete preprocesing dispone de la clase *OneHotEncoder*, que de una forma fácil genera este tipo de variables dummy.\n",
    "\n",
    "Veamos a continuación un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3]\n",
      " [1 1 0]\n",
      " [0 2 1]\n",
      " [1 0 2]]\n",
      "\n",
      "\n",
      "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
      "       handle_unknown='error', n_values='auto', sparse=True) \n",
      "\n",
      "número de categorías para cada columna ( o feature o variable):  [2 3 4]\n",
      "índice o columna a partir del cual se coloca la codificación dummy obtenida:  [0 2 5 9]\n",
      "Salida para [0,1,1]-->  [[1. 0. 0. 1. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "print(np.array([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]))\n",
    "print(\"\\n\")\n",
    "print(enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]),\"\\n\")  \n",
    "\n",
    "\n",
    "print(\"número de categorías para cada columna ( o feature o variable): \",enc.n_values_)  #número de categorías para cada columna ( o feature o variable)\n",
    "\n",
    "print(\"índice o columna a partir del cual se coloca la codificación dummy obtenida: \",enc.feature_indices_) #índice o columna a partir del cual se coloca la codificación dummy obtenida\n",
    "\n",
    "print(\"Salida para [0,1,1]--> \", enc.transform([[0, 1, 1]]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la salida anterior, se puede ver que la columna 1 tiene dos categorías, la columna 2 tiene 3 y la columna 3,  4 categoría ( es el array de salida [2 3 4]). \n",
    "\n",
    "El array de salida [0 2 5 9], indica que al codificar un vector de estas características, las posiciones 0 y 1 ( recordar que en numpy los índices cominezan con cero) son para codificar el primera variable, las posiciones 2,3,4 son para la segunda varible..., etc. \n",
    "\n",
    "Ahora ya se puede interpretar el vector de salidad [[1., 0., 0., 1., 0., 0., 1., 0., 0.]], pues las dos primeras columnas se corresponden con la codificación de la primera Variable ( 0 se codifica como 1 0), las posiciones 2, 3 y 4 son para la codificación del valor de la segunda variable ( 1 se codifica como 0 1 0 ) y el resto de posiciones son para codificar el valor de la tercera variable ( 1 se codifica como 0 1 0 0). \n",
    "\n",
    "## Codificando con pandas.\n",
    "\n",
    "El paquete pandas tiene una opción también para transformar variables categóricas en variables de tipo dummy, la sentencia a utilizar sería similar a la siguiente:\n",
    "\n",
    "*df_with_dummies = pd.get_dummies( df, columns = cols_to_transform )*\n",
    "\n",
    "A continuación se muestra un sencillo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  a  c  1\n",
      "1  b  c  2\n",
      "2  a  b  3 \n",
      "\n",
      "   C  A_a  A_b  B_b  B_c\n",
      "0  1    1    0    0    1\n",
      "1  2    0    1    0    1\n",
      "2  3    1    0    1    0 \n",
      "\n",
      "   B  C  A_a  A_b\n",
      "0  c  1    1    0\n",
      "1  c  2    0    1\n",
      "2  b  3    1    0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['c', 'c', 'b'],\n",
    "                 'C': [1, 2, 3]})\n",
    "print(df,\"\\n\")\n",
    "\n",
    "print(pd.get_dummies(df),\"\\n\")\n",
    "\n",
    "print(pd.get_dummies(df,columns='A') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputando valores faltantes.\n",
    "\n",
    "Por regla general, cuando se trabaja con un fichero de datos, siempres existen imperfecciones en los mismo de todo tipo. Un caso muy frecuente es la falta de valor en algunas observaciones, estos valores faltantes, quedan codificado en numpy como np.nan.\n",
    "\n",
    "Esta falta de valor origina serios problemas en la construcción de modelo si previamente no se ha procedido a su imputación. Son muchos los métodos existentes en la actualidad para proceder a la imputación de los valores omitidos, y scikit learn ofrece la lases *Imputer* para ccorregir esta deficiencia de los datos originales.\n",
    "\n",
    "En ejemplo que sigue se ha procedido a imputar la media para los valores faltantes. Veamos el ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.         2.        ]\n",
      " [6.         3.66666667]\n",
      " [7.         6.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit([[1, 2], [np.nan, 3], [7, 6]])\n",
    "\n",
    "X = [[np.nan, 2], [6, np.nan], [7, 6]]\n",
    "print(imp.transform(X))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando features tipo polinomio\n",
    "\n",
    "En ocasiones, es necesario añadir algun tipo de complejidad al modelo, y para ello, lo que se suele hacer es calcular valores nuevos de las variables, mediante funciones polinómicas. Para facilitar esta labor, se dispone de la clase PolynomialFeatures, cuyo funcionamiento se puede observar en el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "print(X,\"\\n\")                                                 \n",
    "\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el anterior ejemplo, las features iniciales $(X_1,X_2)$, se transforman en $(1,X_1,X_2,X_1^2,X_1*X_2,X_2^2)$.\n",
    "\n",
    "Si sólo se quiere trabajar con la iteración entre las features, se puede indicar con el parámetro \"interaction_onlu=True\". Veamos un ejemplo sobre este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0.,   1.,   2.,   0.,   0.,   2.,   0.],\n",
       "       [  1.,   3.,   4.,   5.,  12.,  15.,  20.,  60.],\n",
       "       [  1.,   6.,   7.,   8.,  42.,  48.,  56., 336.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(9).reshape(3, 3)\n",
    "print(X,\"\\n\")                                                \n",
    "\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=True)\n",
    "poly.fit_transform(X)                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso las variables $(X_1,X_2,X_3)$ se trasforman en $(1,X_1,X_2,X_3,X_1X_2,X_1X_3,X_2X_3,X_1X_2X_3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones a medida.\n",
    "\n",
    "Por último y ya para terminar ese apartado, el paquete preprocessing, tiene la función *FunctioTransformer* que permite modificar los valores iniciales con las funciones que en cada momento puedan ser necesarias. A continuación se muestra un ejemplo sobre su uso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.69314718],\n",
       "       [1.09861229, 1.38629436]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p) #Utiliza la función log1p para transformar todos los datos\n",
    "X = np.array([[0, 1], [2, 3]])\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      "\n",
      "0.6931471805599453 \n",
      "\n",
      "1.0986122886681098 \n",
      "\n",
      "1.3862943611198906 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.log1p(X[0,0]),\"\\n\")\n",
    "print(np.log1p(X[0,1]),\"\\n\")\n",
    "print(np.log1p(X[1,0]),\"\\n\")\n",
    "print(np.log1p(X[1,1]),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, se muestra un ejemplo mucho más elaborado sobre la transformación de los datos con numpy y scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "def _generate_vector(shift=0.5, noise=15):\n",
    "    return np.arange(1000) + (np.random.rand(1000) - shift) * noise\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    \"\"\"\n",
    "    This dataset is two lines with a slope ~ 1, where one has\n",
    "    a y offset of ~100\n",
    "    \"\"\"\n",
    "    return np.vstack((\n",
    "        np.vstack((\n",
    "            _generate_vector(),\n",
    "            _generate_vector() + 100,\n",
    "        )).T,\n",
    "        np.vstack((\n",
    "            _generate_vector(),\n",
    "            _generate_vector(),\n",
    "        )).T,\n",
    "    )), np.hstack((np.zeros(1000), np.ones(1000)))\n",
    "\n",
    "\n",
    "def all_but_first_column(X):\n",
    "    return X[:, 1:]\n",
    "\n",
    "\n",
    "def drop_first_component(X, y):\n",
    "    \"\"\"\n",
    "    Create a pipeline with PCA and the column selector and use it to\n",
    "    transform the dataset.\n",
    "    \"\"\"\n",
    "    pipeline = make_pipeline(\n",
    "        PCA(), FunctionTransformer(all_but_first_column),\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return pipeline.transform(X_test), y_test\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, y = generate_dataset()\n",
    "    lw = 0\n",
    "    plt.figure()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, lw=lw)\n",
    "    plt.figure()\n",
    "    X_transformed, y_transformed = drop_first_component(*generate_dataset())\n",
    "    plt.scatter(\n",
    "        X_transformed[:, 0],\n",
    "        np.zeros(len(X_transformed)),\n",
    "        c=y_transformed,\n",
    "        lw=lw,\n",
    "        s=60\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "237px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
